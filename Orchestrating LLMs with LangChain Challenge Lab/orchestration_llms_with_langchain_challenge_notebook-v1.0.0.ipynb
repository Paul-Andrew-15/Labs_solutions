{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde76e4d-feb7-4e16-b1bd-8fb6a833cc0c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Task 2. Install packages and import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0996bc96-204e-4c32-9963-edb0a821dd63",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Install Vertex AI SDK & Other dependencies\n",
    "\n",
    "!sudo apt -y -qq install tesseract-ocr\n",
    "!sudo apt -y -qq install libtesseract-dev\n",
    "!sudo apt-get -y -qq install poppler-utils #required by PyPDF2 for page count and other pdf utilities\n",
    "!sudo apt-get -y -qq install python-dev libxml2-dev libxslt1-dev antiword unrtf poppler-utils tesseract-ocr flac ffmpeg lame libmad0 libsox-fmt-mp3 sox libjpeg-dev swig\n",
    "!pip install langchain langchain-community langchain-core langchain-google-vertexai pypdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b36a8e4-ea7b-410b-ae11-1275b662ce1f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Automatically restart kernel after installs so that your environment can access the new packages\n",
    "import IPython\n",
    "\n",
    "app = IPython.Application.instance()\n",
    "\n",
    "app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e22b08-4adc-4fb9-95b5-ec7fb7f6a261",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "\n",
    "import urllib\n",
    "import warnings\n",
    "from pathlib import Path as p\n",
    "\n",
    "import pandas as pd\n",
    "from langchain import PromptTemplate\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain_google_vertexai import ChatVertexAI\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc6f525-9786-4569-aaac-9c005db08b5c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Task 3. Load the model and prepare data\n",
    "from langchain_google_vertexai import ChatVertexAI\n",
    "\n",
    "# Load the pre-trained model\n",
    "model = ChatVertexAI(model_name=\"gemini-pro\")\n",
    "#TODO: Load the pre-trained text generation model named gemini-pro using ChatVertexAI.\n",
    "#TODO: Load the pre-trained text generation model named Quicklab using ChatVertexAI.\n",
    "import urllib.request\n",
    "from pathlib import Path\n",
    "\n",
    "# Define the URL and local path\n",
    "url = \"https://services.google.com/fh/files/misc/practitioners_guide_to_mlops_whitepaper.pdf\"\n",
    "local_path = Path(\"data/practitioners_guide_to_mlops_whitepaper.pdf\")\n",
    "\n",
    "# Create the 'data' directory if it doesn't exist\n",
    "local_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Download and save the PDF file\n",
    "urllib.request.urlretrieve(url, local_path)\n",
    "\n",
    "#TODO: Download a PDF file from specified URL and save it in \"data\" directory\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "# Load the PDF file\n",
    "pdf_loader = PyPDFLoader(str(local_path))\n",
    "\n",
    "# Load and split the PDF into individual pages\n",
    "pages = pdf_loader.load_and_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d03b7b86-4b03-43e7-80f3-a2465a78da56",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#TODO: Load the pre-trained text generation model named \"gemini-1.5-pro\" using \"ChatVertexAI\" class.\n",
    "from langchain_google_vertexai import ChatVertexAI\n",
    "\n",
    "# Load the pre-trained model\n",
    "model = ChatVertexAI(model_name=\"gemini-1.5-pro\")\n",
    "#TODO: Load the pre-trained text generation model named gemini-pro using ChatVertexAI.\n",
    "#TODO: Load the pre-trained text generation model named Quicklab using ChatVertexAI.\n",
    "import urllib.request\n",
    "from pathlib import Path\n",
    "\n",
    "# Define the URL and local path\n",
    "url = \"https://services.google.com/fh/files/misc/practitioners_guide_to_mlops_whitepaper.pdf\"\n",
    "local_path = Path(\"data/practitioners_guide_to_mlops_whitepaper.pdf\")\n",
    "\n",
    "# Create the 'data' directory if it doesn't exist\n",
    "local_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Download and save the PDF file\n",
    "urllib.request.urlretrieve(url, local_path)\n",
    "\n",
    "#TODO: Download a PDF file from specified URL and save it in \"data\" directory\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "# Load the PDF file\n",
    "pdf_loader = PyPDFLoader(str(local_path))\n",
    "\n",
    "# Load and split the PDF into individual pages\n",
    "pages = pdf_loader.load_and_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597fe978-801d-4e91-bbdd-470b55d19843",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#TODO: Download a PDF file from specified URL and save it in \"data\" directory.\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import vertexai\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.llms.vertexai import VertexAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "from langchain import PromptTemplate\n",
    "from langchain_google_vertexai import ChatVertexAI\n",
    "from langchain.chains import load_summarize_chain\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "import urllib.request\n",
    "from pathlib import Path\n",
    "\n",
    "# Define the URL and local path\n",
    "url = \"https://services.google.com/fh/files/misc/practitioners_guide_to_mlops_whitepaper.pdf\"\n",
    "local_path = Path(\"data/practitioners_guide_to_mlops_whitepaper.pdf\")\n",
    "\n",
    "# Create the 'data' directory if it doesn't exist\n",
    "local_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Download and save the PDF file\n",
    "urllib.request.urlretrieve(url, local_path)\n",
    "\n",
    "# Load the PDF file\n",
    "pdf_loader = PyPDFLoader(str(local_path))\n",
    "\n",
    "# Load and split the PDF into individual pages\n",
    "pages = pdf_loader.load_and_split()\n",
    "\n",
    "# Prepare the prompt template\n",
    "prompt_template = \"\"\"Write a concise summary of the following text delimited by triple backquotes.\n",
    "              Return your response in bullet points which covers the key points of the text.\n",
    "              ```{text}```\n",
    "              BULLET POINT SUMMARY:\n",
    "  \"\"\"\n",
    "\n",
    "prompt = PromptTemplate(template=prompt_template, input_variables=[\"text\"])\n",
    "\n",
    "# Initialize the pre-trained model\n",
    "model = ChatVertexAI(model_name=\"gemini-pro\")\n",
    "\n",
    "# Load the summarization chain with the stuff method\n",
    "summarization_chain = load_summarize_chain(\n",
    "    llm=model,\n",
    "    chain_type=\"stuff\",\n",
    "    prompt=prompt\n",
    ")\n",
    "\n",
    "# Prepare the first three pages as documents\n",
    "input_documents = pages[:3]  # Use first three Document objects\n",
    "\n",
    "# Generate the summary\n",
    "summary = summarization_chain({\"input_documents\": input_documents})\n",
    "\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ca3eec-f83a-4400-8e22-ada41ca45857",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "from langchain_google_vertexai import ChatVertexAI\n",
    "\n",
    "llm = ChatVertexAI(model=\"gemini-pro\")\n",
    "import getpass\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd0e50b-3ee8-47fc-a275-0ace00df6609",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#TODO: Load the PDF file and split it into individual pages.\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "\n",
    "@tool\n",
    "def add(a: int, b: int) -> int:\n",
    "    \"\"\"Adds a and b.\n",
    "\n",
    "    Args:\n",
    "        a: first int\n",
    "        b: second int\n",
    "    \"\"\"\n",
    "    return a + b\n",
    "\n",
    "\n",
    "@tool\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiplies a and b.\n",
    "\n",
    "    Args:\n",
    "        a: first int\n",
    "        b: second int\n",
    "    \"\"\"\n",
    "    return a * b\n",
    "\n",
    "\n",
    "tools = [add, multiply]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb18acd5-29e8-4d16-ac00-0d27b740f99f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Task 4. Generate summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de464893-f82f-4be1-a37e-d8e4d0f57d7f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Prompt design with Stuffing Chain\n",
    "\n",
    "prompt_template = \"\"\"Write a concise summary of the following text delimited by triple backquotes.\n",
    "              Return your response in bullet points which covers the key points of the text.\n",
    "              ```{text}```\n",
    "              BULLET POINT SUMMARY:\n",
    "  \"\"\"\n",
    "\n",
    "prompt = PromptTemplate(template=prompt_template, input_variables=[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6071ad9f-f764-4eac-a5b2-4c7bcd583269",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#TODO: Add the tools to the LLM created earlier and invoke it with the following query. Print the result in the console.\n",
    "from langchain_core.messages import HumanMessage, ToolMessage, AIMessage\n",
    "query = \"What is 3 * 12?\"\n",
    "messages = [HumanMessage(query)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e0caff-57f4-4782-be24-d2050aae602b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#TODO: Iterate through the tools in the response, invoke the tools and append the response to the messages object.\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "always_multiply_llm = llm.bind_tools([multiply], tool_choice=\"multiply\")\n",
    "always_call_tool_llm = llm.bind_tools([add, multiply], tool_choice=\"any\")\n",
    "query = \"What is 3 * 12?\"\n",
    "\n",
    "llm_with_tools.invoke(query).tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433d86ac-087c-4ba5-a4ba-2c38b3fb99d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#TODO: Invoke the LLM with the solution of the tool and the original message and print the final user response.\n",
    "from langchain_core.output_parsers.openai_tools import PydanticToolsParser\n",
    "from langchain_core.messages import HumanMessage, ToolMessage\n",
    "\n",
    "\n",
    "@tool\n",
    "def add(a: int, b: int) -> int:\n",
    "    \"\"\"Adds a and b.\n",
    "\n",
    "    Args:\n",
    "        a: first int\n",
    "        b: second int\n",
    "    \"\"\"\n",
    "    return a + b\n",
    "\n",
    "\n",
    "@tool\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiplies a and b.\n",
    "\n",
    "    Args:\n",
    "        a: first int\n",
    "        b: second int\n",
    "    \"\"\"\n",
    "    return a * b\n",
    "\n",
    "\n",
    "tools = [add, multiply]\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "messages = [HumanMessage(query)]\n",
    "ai_msg = llm_with_tools.invoke(messages)\n",
    "messages.append(ai_msg)\n",
    "\n",
    "for tool_call in ai_msg.tool_calls:\n",
    "    selected_tool = {\"add\": add, \"multiply\": multiply}[tool_call[\"name\"].lower()]\n",
    "    tool_output = selected_tool.invoke(tool_call[\"args\"])\n",
    "    messages.append(ToolMessage(tool_output, tool_call_id=tool_call[\"id\"]))\n",
    "\n",
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab94cef4-19ac-44af-ba75-b938badf6997",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m127",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m127"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
